## v1.0.0

This release improves the reliability and safety of generated changelogs and release notes, and adds a first-class, automated prepublish/postpublish release flow. It also introduces richer logging and Azure/OpenAI client enhancements for more robust, debuggable runs.

### Highlights
- Added a Keep a Changelog–style renderer and a dedicated release-notes renderer so generated markdown is consistently structured, omits empty sections, and normalizes headings and summaries. 
- Extended the release-notes pipeline to optionally include bounded git commit context, improving the quality of summaries without treating commit messages as authoritative.
- Enhanced the prepublish pipeline to automatically compute the next semantic version, validate the model’s version-bump reasoning, and generate both changelog entries and release notes for the predicted tag.
- Exposed new `prepublish` and `postpublish` npm scripts that build the project and then run the corresponding automated release flows via the CLI.
- Improved documentation for the multi-pass LLM architecture, authority rules for diffs vs. repo context, and the end-to-end prepublish/postpublish workflow.

### Fixes
- Refined breaking-change detection to flag cases where an optional property in an exported type becomes required, reducing the risk of missing subtle TypeScript API breaks.
- Tightened Azure Structured Outputs support to reject unsupported API versions with a clear error instead of failing at runtime.

### Security
- Enforced stricter rules around what the model can treat as authoritative (diffs only) and how commit context is used, reducing the risk of misleading or injected information influencing generated notes.

### Performance
- Introduced configurable, budget-aware limits for diff hunks, repo context, and commit-context collection so large changesets can be processed efficiently without exceeding size constraints.
- Added structured, configurable logging (including optional LLM output tracing) to make it easier to diagnose performance issues and tune behavior in different environments.
- Updated Azure OpenAI and OpenAI clients to support streaming responses and smarter retries when JSON outputs are truncated, improving robustness and responsiveness for long generations.
